#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
DailycheckBot2025 - Dashboard Dependencies
–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏, middleware –∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –¥–ª—è FastAPI –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–ê–≤—Ç–æ—Ä: AI Assistant
–í–µ—Ä—Å–∏—è: 1.0.0
–î–∞—Ç–∞: 2025-06-10
"""

import asyncio
import time
import logging
import os
import sys
import hashlib
import json
import secrets
from typing import Optional, Dict, Any, Generator, AsyncGenerator, List, Union
from functools import lru_cache, wraps
from contextlib import asynccontextmanager
from datetime import datetime, timedelta
from pathlib import Path

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logger = logging.getLogger(__name__)

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ Redis
try:
    import redis.asyncio as redis
    REDIS_AVAILABLE = True
    RedisType = redis.Redis
except ImportError:
    REDIS_AVAILABLE = False
    RedisType = type(None)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º type(None) –≤–º–µ—Å—Ç–æ None –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏
    redis = None
    logger.warning("‚ö†Ô∏è Redis –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º in-memory –∫—ç—à")

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ SQLAlchemy
try:
    from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
    from sqlalchemy.orm import sessionmaker
    SQLALCHEMY_AVAILABLE = True
except ImportError:
    SQLALCHEMY_AVAILABLE = False
    AsyncSession = type(None)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º type(None) –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏
    logger.warning("‚ö†Ô∏è SQLAlchemy –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω, –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Ç–∫–ª—é—á–µ–Ω–∞")

from fastapi import Depends, HTTPException, Request, status, BackgroundTasks
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
try:
    from dashboard.config import settings
except ImportError:
    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    class Settings:
        DATA_DIR = Path('./data')
        REDIS_URL = os.getenv('REDIS_URL')
        DATABASE_URL = os.getenv('DATABASE_URL')
        TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
        ADMIN_USER_IDS = [int(x) for x in os.getenv('ADMIN_USER_IDS', '').split(',') if x.strip()]
        CACHE_ENABLED = os.getenv('CACHE_ENABLED', 'true').lower() == 'true'
        CACHE_TTL = int(os.getenv('CACHE_TTL', '300'))
        API_RATE_LIMIT = os.getenv('API_RATE_LIMIT', '100/minute')
        DB_POOL_SIZE = int(os.getenv('DB_POOL_SIZE', '10'))
        DB_MAX_OVERFLOW = int(os.getenv('DB_MAX_OVERFLOW', '20'))
        DEBUG = os.getenv('DEBUG', 'False').lower() == 'true'
        ENVIRONMENT = os.getenv('ENVIRONMENT', 'production')
        SECRET_KEY = os.getenv('SECRET_KEY', secrets.token_urlsafe(32))
    
    settings = Settings()

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ core –º–æ–¥—É–ª–µ–π
try:
    from dashboard.core.data_manager import DataManager
except ImportError:
    # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è DataManager
    class DataManager:
        def __init__(self, data_dir):
            self.data_dir = Path(data_dir)
            self.data_dir.mkdir(exist_ok=True)
        
        async def initialize(self):
            pass
        
        async def cleanup(self):
            pass
        
        async def get_users_count(self):
            return 0
        
        async def get_tasks_count(self):
            return 0

try:
    from dashboard.core.statistics import StatisticsCalculator
except ImportError:
    class StatisticsCalculator:
        def __init__(self, data_manager):
            self.data_manager = data_manager
        
        async def initialize(self):
            pass
        
        async def cleanup(self):
            pass

try:
    from dashboard.core.analytics import AnalyticsEngine
except ImportError:
    class AnalyticsEngine:
        def __init__(self, data_manager, stats_calculator):
            self.data_manager = data_manager
            self.stats_calculator = stats_calculator
        
        async def initialize(self):
            pass
        
        async def cleanup(self):
            pass

logger = logging.getLogger(__name__)

# ===== –ì–õ–û–ë–ê–õ–¨–ù–´–ï –ü–ï–†–ï–ú–ï–ù–ù–´–ï =====

# –°–∏–Ω–≥–ª—Ç–æ–Ω—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
_data_manager: Optional[DataManager] = None
_statistics_calculator: Optional[StatisticsCalculator] = None
_analytics_engine: Optional[AnalyticsEngine] = None
_redis_client: Optional[RedisType] = None
_db_engine = None
_db_session_factory = None

# –°–æ—Å—Ç–æ—è–Ω–∏–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
_initialized = False
_initialization_lock = asyncio.Lock()

# ===== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ö–û–ú–ü–û–ù–ï–ù–¢–û–í =====

async def ensure_initialized():
    """–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã"""
    global _initialized
    
    if _initialized:
        return
    
    async with _initialization_lock:
        if _initialized:
            return
        
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ dashboard...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø–æ –ø–æ—Ä—è–¥–∫—É
        await init_data_manager()
        await init_redis()
        await init_database()
        await init_statistics_calculator()
        await init_analytics_engine()
        
        _initialized = True
        logger.info("‚úÖ –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã dashboard –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

async def init_data_manager() -> DataManager:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    global _data_manager
    
    if _data_manager is None:
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è DataManager...")
        try:
            _data_manager = DataManager(settings.DATA_DIR)
            await _data_manager.initialize()
            logger.info("‚úÖ DataManager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ DataManager: {e}")
            raise
    
    return _data_manager

async def init_statistics_calculator() -> StatisticsCalculator:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
    global _statistics_calculator
    
    if _statistics_calculator is None:
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StatisticsCalculator...")
        try:
            data_manager = await get_data_manager()
            _statistics_calculator = StatisticsCalculator(data_manager)
            await _statistics_calculator.initialize()
            logger.info("‚úÖ StatisticsCalculator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ StatisticsCalculator: {e}")
            raise
    
    return _statistics_calculator

async def init_analytics_engine() -> AnalyticsEngine:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–≤–∏–∂–∫–∞"""
    global _analytics_engine
    
    if _analytics_engine is None:
        logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AnalyticsEngine...")
        try:
            data_manager = await get_data_manager()
            stats_calculator = await get_statistics_calculator()
            _analytics_engine = AnalyticsEngine(data_manager, stats_calculator)
            await _analytics_engine.initialize()
            logger.info("‚úÖ AnalyticsEngine –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AnalyticsEngine: {e}")
            raise
    
    return _analytics_engine

async def init_redis() -> Optional[RedisType]:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global _redis_client
    
    if not REDIS_AVAILABLE or not settings.REDIS_URL:
        return None
    
    if _redis_client is None:
        try:
            logger.info("üîÑ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis...")
            _redis_client = redis.from_url(
                settings.REDIS_URL,
                encoding="utf-8",
                decode_responses=True,
                max_connections=10,
                socket_connect_timeout=5,
                socket_timeout=5,
                retry_on_timeout=True
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ
            await _redis_client.ping()
            logger.info("‚úÖ Redis –ø–æ–¥–∫–ª—é—á–µ–Ω")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Redis: {e}")
            _redis_client = None
    
    return _redis_client

async def init_database() -> Optional[AsyncSession]:
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
    global _db_engine, _db_session_factory
    
    if not SQLALCHEMY_AVAILABLE or not settings.DATABASE_URL:
        return None
    
    if _db_engine is None:
        try:
            logger.info("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
            
            _db_engine = create_async_engine(
                settings.DATABASE_URL,
                pool_size=settings.DB_POOL_SIZE,
                max_overflow=settings.DB_MAX_OVERFLOW,
                echo=settings.DEBUG,
                future=True
            )
            
            _db_session_factory = async_sessionmaker(
                _db_engine,
                class_=AsyncSession,
                expire_on_commit=False
            )
            
            logger.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ë–î: {e}")
            _db_engine = None
            _db_session_factory = None
    
    return _db_session_factory

# ===== –ü–†–û–í–ê–ô–î–ï–†–´ –ó–ê–í–ò–°–ò–ú–û–°–¢–ï–ô =====

async def get_data_manager() -> DataManager:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä DataManager"""
    await ensure_initialized()
    if _data_manager is None:
        raise HTTPException(
            status_code=503,
            detail="DataManager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
        )
    return _data_manager

async def get_statistics_calculator() -> StatisticsCalculator:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä StatisticsCalculator"""
    await ensure_initialized()
    if _statistics_calculator is None:
        raise HTTPException(
            status_code=503,
            detail="StatisticsCalculator –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
        )
    return _statistics_calculator

async def get_analytics_engine() -> AnalyticsEngine:
    """–ü–æ–ª—É—á–∏—Ç—å —ç–∫–∑–µ–º–ø–ª—è—Ä AnalyticsEngine"""
    await ensure_initialized()
    if _analytics_engine is None:
        raise HTTPException(
            status_code=503,
            detail="AnalyticsEngine –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω"
        )
    return _analytics_engine

async def get_redis() -> Optional[RedisType]:
    """–ü–æ–ª—É—á–∏—Ç—å Redis –∫–ª–∏–µ–Ω—Ç"""
    await ensure_initialized()
    return _redis_client

async def get_db_session():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–µ—Å—Å–∏—é –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    await ensure_initialized()
    
    if not _db_session_factory:
        yield None
        return
    
    async with _db_session_factory() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

# ===== –ö–≠–®–ò–†–û–í–ê–ù–ò–ï =====

class InMemoryCache:
    """–ü—Ä–æ—Å—Ç–æ–π –∫—ç—à –≤ –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, default_ttl: int = 300):
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.default_ttl = default_ttl
    
    async def get(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞"""
        if key not in self.cache:
            return None
        
        item = self.cache[key]
        if time.time() - item['timestamp'] > item['ttl']:
            del self.cache[key]
            return None
        
        return item['data']
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à"""
        self.cache[key] = {
            'data': value,
            'timestamp': time.time(),
            'ttl': ttl or self.default_ttl
        }
    
    async def delete(self, key: str) -> None:
        """–£–¥–∞–ª–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞"""
        if key in self.cache:
            del self.cache[key]
    
    async def clear(self) -> None:
        """–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å –∫—ç—à"""
        self.cache.clear()
    
    async def cleanup(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π"""
        current_time = time.time()
        expired_keys = [
            key for key, item in self.cache.items()
            if current_time - item['timestamp'] > item['ttl']
        ]
        
        for key in expired_keys:
            del self.cache[key]

class CacheManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"""
    
    def __init__(self, redis_client: Optional[RedisType] = None):
        self.redis = redis_client
        self.memory_cache = InMemoryCache(settings.CACHE_TTL)
        self.cache_ttl = settings.CACHE_TTL
        self.enabled = settings.CACHE_ENABLED
    
    async def get(self, key: str) -> Optional[Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞"""
        if not self.enabled:
            return None
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º Redis
        if self.redis:
            try:
                value = await self.redis.get(key)
                if value:
                    return json.loads(value)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∏–∑ Redis: {e}")
        
        # Fallback –Ω–∞ –ø–∞–º—è—Ç—å
        return await self.memory_cache.get(key)
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∫—ç—à"""
        if not self.enabled:
            return
        
        ttl = ttl or self.cache_ttl
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Redis
        if self.redis:
            try:
                serialized_value = json.dumps(value, default=str, ensure_ascii=False)
                await self.redis.setex(key, ttl, serialized_value)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ –≤ Redis: {e}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
        await self.memory_cache.set(key, value, ttl)
    
    async def delete(self, key: str) -> None:
        """–£–¥–∞–ª–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫—ç—à–∞"""
        if self.redis:
            try:
                await self.redis.delete(key)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ Redis: {e}")
        
        await self.memory_cache.delete(key)
    
    async def clear(self) -> None:
        """–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å –∫—ç—à"""
        if self.redis:
            try:
                await self.redis.flushdb()
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ Redis: {e}")
        
        await self.memory_cache.clear()
    
    async def cleanup(self) -> None:
        """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞"""
        await self.memory_cache.cleanup()
    
    def cache_key(self, *args, **kwargs) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–ª—é—á–∞ –∫—ç—à–∞"""
        key_data = {
            'args': args,
            'kwargs': kwargs,
            'timestamp': int(time.time() / 60)  # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
        }
        key_str = json.dumps(key_data, sort_keys=True, default=str)
        return hashlib.md5(key_str.encode()).hexdigest()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –∫—ç—à –º–µ–Ω–µ–¥–∂–µ—Ä
_cache_manager: Optional[CacheManager] = None

async def get_cache_manager() -> CacheManager:
    """–ü–æ–ª—É—á–∏—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
    global _cache_manager
    
    if _cache_manager is None:
        redis_client = await get_redis()
        _cache_manager = CacheManager(redis_client)
    
    return _cache_manager

def cached(ttl: int = 300, key_prefix: str = ""):
    """–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            cache = await get_cache_manager()
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–ª—é—á –∫—ç—à–∞
            cache_key = f"{key_prefix}:{func.__name__}:{cache.cache_key(*args, **kwargs)}"
            
            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞
            cached_result = await cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –∏ –∫—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = await func(*args, **kwargs)
            await cache.set(cache_key, result, ttl)
            
            return result
        
        return wrapper
    return decorator

# ===== –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø =====

security = HTTPBearer(auto_error=False)

class TelegramAuth:
    """–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Telegram Web App"""
    
    def __init__(self):
        self.bot_token = settings.TELEGRAM_BOT_TOKEN
        self.admin_ids = settings.ADMIN_USER_IDS
        self.secret_key = settings.SECRET_KEY
    
    def verify_telegram_hash(self, init_data: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–ø–∏—Å–∏ –¥–∞–Ω–Ω—ã—Ö Telegram Web App"""
        if not self.bot_token:
            return False
        
        try:
            import hmac
            
            # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
            data_dict = {}
            for item in init_data.split('&'):
                key, value = item.split('=', 1)
                data_dict[key] = value
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º hash
            received_hash = data_dict.pop('hash', '')
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
            check_string = '&'.join([f"{k}={v}" for k, v in sorted(data_dict.items())])
            
            # –í—ã—á–∏—Å–ª—è–µ–º hash
            secret_key = hmac.new(
                "WebAppData".encode(),
                self.bot_token.encode(),
                hashlib.sha256
            ).digest()
            
            calculated_hash = hmac.new(
                secret_key,
                check_string.encode(),
                hashlib.sha256
            ).hexdigest()
            
            return calculated_hash == received_hash
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ Telegram hash: {e}")
            return False
    
    async def verify_telegram_data(self, init_data: str) -> Optional[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö Telegram Web App"""
        if not self.verify_telegram_hash(init_data):
            return None
        
        try:
            # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            data_dict = {}
            for item in init_data.split('&'):
                key, value = item.split('=', 1)
                data_dict[key] = value
            
            user_data = json.loads(data_dict.get('user', '{}'))
            
            return {
                'user_id': user_data.get('id'),
                'username': user_data.get('username'),
                'first_name': user_data.get('first_name'),
                'last_name': user_data.get('last_name'),
                'is_admin': user_data.get('id') in self.admin_ids
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ Telegram –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def is_admin(self, user_id: int) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–∞–≤ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
        return user_id in self.admin_ids
    
    def create_session_token(self, user_data: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞ —Å–µ—Å—Å–∏–∏"""
        import jwt
        
        payload = {
            'user_id': user_data['user_id'],
            'username': user_data.get('username'),
            'is_admin': user_data.get('is_admin', False),
            'exp': datetime.utcnow() + timedelta(hours=24),
            'iat': datetime.utcnow()
        }
        
        return jwt.encode(payload, self.secret_key, algorithm='HS256')
    
    def verify_session_token(self, token: str) -> Optional[Dict[str, Any]]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–∫–µ–Ω–∞ —Å–µ—Å—Å–∏–∏"""
        try:
            import jwt
            
            payload = jwt.decode(token, self.secret_key, algorithms=['HS256'])
            return payload
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–∞: {e}")
            return None

telegram_auth = TelegramAuth()

async def get_current_user(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)
) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if not credentials:
        return None
    
    token = credentials.credentials
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–∫–µ–Ω —Å–µ—Å—Å–∏–∏
    user_data = telegram_auth.verify_session_token(token)
    if user_data:
        return user_data
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Telegram –¥–∞–Ω–Ω—ã–µ
    user_data = await telegram_auth.verify_telegram_data(token)
    return user_data

async def get_optional_user(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security)
) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)"""
    try:
        return await get_current_user(credentials)
    except:
        return None

async def require_auth(
    current_user: Optional[Dict[str, Any]] = Depends(get_current_user)
) -> Dict[str, Any]:
    """–¢—Ä–µ–±–æ–≤–∞—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏"""
    if not current_user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–¢—Ä–µ–±—É–µ—Ç—Å—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è",
            headers={"WWW-Authenticate": "Bearer"}
        )
    return current_user

async def require_admin(
    current_user: Dict[str, Any] = Depends(require_auth)
) -> Dict[str, Any]:
    """–¢—Ä–µ–±–æ–≤–∞—Ç—å –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"""
    if not current_user.get('is_admin', False):
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="–¢—Ä–µ–±—É—é—Ç—Å—è –ø—Ä–∞–≤–∞ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞"
        )
    return current_user

# ===== RATE LIMITING =====

class RateLimiter:
    """Rate limiter —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Redis –∏ –ø–∞–º—è—Ç–∏"""
    
    def __init__(self, redis_client: Optional[RedisType] = None):
        self.redis = redis_client
        self.memory_store: Dict[str, List[float]] = {}
        self.limits = self._parse_limit(settings.API_RATE_LIMIT)
    
    def _parse_limit(self, limit_str: str) -> Dict[str, int]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–∏ –ª–∏–º–∏—Ç–∞"""
        try:
            count, period = limit_str.split('/')
            period_seconds = {
                'second': 1,
                'minute': 60,
                'hour': 3600,
                'day': 86400
            }.get(period, 60)
            
            return {'count': int(count), 'period': period_seconds}
        except Exception:
            return {'count': 100, 'period': 60}
    
    async def is_allowed(self, client_id: str, limit_override: Optional[Dict[str, int]] = None) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        limits = limit_override or self.limits
        current_time = time.time()
        
        # –ü—Ä–æ–±—É–µ–º Redis
        if self.redis:
            try:
                return await self._check_redis_limit(client_id, current_time, limits)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ª–∏–º–∏—Ç–∞ –≤ Redis: {e}")
        
        # Fallback –Ω–∞ –ø–∞–º—è—Ç—å
        return await self._check_memory_limit(client_id, current_time, limits)
    
    async def _check_redis_limit(self, client_id: str, current_time: float, limits: Dict[str, int]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –≤ Redis"""
        key = f"rate_limit:{client_id}"
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º sliding window
        await self.redis.zremrangebyscore(key, 0, current_time - limits['period'])
        
        current_count = await self.redis.zcard(key)
        
        if current_count >= limits['count']:
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        await self.redis.zadd(key, {str(current_time): current_time})
        await self.redis.expire(key, limits['period'])
        
        return True
    
    async def _check_memory_limit(self, client_id: str, current_time: float, limits: Dict[str, int]) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–∏–º–∏—Ç–∞ –≤ –ø–∞–º—è—Ç–∏"""
        if client_id not in self.memory_store:
            self.memory_store[client_id] = []
        
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
        cutoff_time = current_time - limits['period']
        self.memory_store[client_id] = [
            req_time for req_time in self.memory_store[client_id]
            if req_time > cutoff_time
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç
        if len(self.memory_store[client_id]) >= limits['count']:
            return False
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        self.memory_store[client_id].append(current_time)
        return True
    
    async def get_remaining(self, client_id: str) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤"""
        current_time = time.time()
        
        if self.redis:
            try:
                key = f"rate_limit:{client_id}"
                await self.redis.zremrangebyscore(key, 0, current_time - self.limits['period'])
                current_count = await self.redis.zcard(key)
                return max(0, self.limits['count'] - current_count)
            except Exception:
                pass
        
        # Fallback –Ω–∞ –ø–∞–º—è—Ç—å
        if client_id in self.memory_store:
            cutoff_time = current_time - self.limits['period']
            current_requests = [
                req_time for req_time in self.memory_store[client_id]
                if req_time > cutoff_time
            ]
            return max(0, self.limits['count'] - len(current_requests))
        
        return self.limits['count']

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π rate limiter
_rate_limiter: Optional[RateLimiter] = None

async def get_rate_limiter() -> RateLimiter:
    """–ü–æ–ª—É—á–∏—Ç—å rate limiter"""
    global _rate_limiter
    
    if _rate_limiter is None:
        redis_client = await get_redis()
        _rate_limiter = RateLimiter(redis_client)
    
    return _rate_limiter

async def check_rate_limit(
    request: Request,
    rate_limiter: RateLimiter = Depends(get_rate_limiter)
) -> None:
    """Middleware –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ rate limit"""
    client_ip = get_client_ip(request)
    
    if not await rate_limiter.is_allowed(client_ip):
        remaining = await rate_limiter.get_remaining(client_ip)
        
        raise HTTPException(
            status_code=status.HTTP_429_TOO_MANY_REQUESTS,
            detail="–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤",
            headers={
                "X-RateLimit-Remaining": str(remaining),
                "X-RateLimit-Reset": str(int(time.time() + 60)),
                "Retry-After": "60"
            }
        )

# ===== –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –ú–ï–¢–†–ò–ö–ò =====

class MetricsCollector:
    """–°–±–æ—Ä—â–∏–∫ –º–µ—Ç—Ä–∏–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    
    def __init__(self):
        self.metrics: Dict[str, Any] = {
            'requests_total': 0,
            'requests_by_endpoint': {},
            'requests_by_method': {},
            'response_times': [],
            'errors_total': 0,
            'errors_by_status': {},
            'cache_hits': 0,
            'cache_misses': 0,
            'active_connections': 0,
            'db_queries': 0
        }
        self.start_time = time.time()
        self._lock = asyncio.Lock()
    
    async def record_request(self, method: str, endpoint: str, response_time: float, status_code: int):
        """–ó–∞–ø–∏—Å–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –∑–∞–ø—Ä–æ—Å–∞"""
        async with self._lock:
            self.metrics['requests_total'] += 1
            
            # –ü–æ endpoint
            if endpoint not in self.metrics['requests_by_endpoint']:
                self.metrics['requests_by_endpoint'][endpoint] = 0
            self.metrics['requests_by_endpoint'][endpoint] += 1
            
            # –ü–æ –º–µ—Ç–æ–¥—É
            if method not in self.metrics['requests_by_method']:
                self.metrics['requests_by_method'][method] = 0
            self.metrics['requests_by_method'][method] += 1
            
            # –í—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
            self.metrics['response_times'].append(response_time)
            
            # –û—à–∏–±–∫–∏
            if status_code >= 400:
                self.metrics['errors_total'] += 1
                if status_code not in self.metrics['errors_by_status']:
                    self.metrics['errors_by_status'][status_code] = 0
                self.metrics['errors_by_status'][status_code] += 1
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Ä–µ–º–µ–Ω –æ—Ç–≤–µ—Ç–∞
            if len(self.metrics['response_times']) > 1000:
                self.metrics['response_times'] = self.metrics['response_times'][-1000:]
    
    async def record_cache_hit(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –∫—ç—à"""
        async with self._lock:
            self.metrics['cache_hits'] += 1
    
    async def record_cache_miss(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å –ø—Ä–æ–º–∞—Ö –∫—ç—à–∞"""
        async with self._lock:
            self.metrics['cache_misses'] += 1
    
    async def record_db_query(self):
        """–ó–∞–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∫ –ë–î"""
        async with self._lock:
            self.metrics['db_queries'] += 1
    
    async def get_metrics(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∏—Ç—å –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏"""
        async with self._lock:
            uptime = time.time() - self.start_time
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞
            response_times = self.metrics['response_times']
            avg_response_time = sum(response_times) / len(response_times) if response_times else 0
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞
            total_cache_requests = self.metrics['cache_hits'] + self.metrics['cache_misses']
            cache_hit_rate = (
                self.metrics['cache_hits'] / total_cache_requests
                if total_cache_requests > 0 else 0
            )
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—à–∏–±–æ–∫
            error_rate = (
                self.metrics['errors_total'] / self.metrics['requests_total']
                if self.metrics['requests_total'] > 0 else 0
            )
            
            return {
                **self.metrics,
                'uptime_seconds': uptime,
                'avg_response_time': avg_response_time,
                'cache_hit_rate': cache_hit_rate,
                'error_rate': error_rate,
                'requests_per_second': self.metrics['requests_total'] / uptime if uptime > 0 else 0
            }
    
    async def reset_metrics(self):
        """–°–±—Ä–æ—Å –º–µ—Ç—Ä–∏–∫"""
        async with self._lock:
            self.metrics = {
                'requests_total': 0,
                'requests_by_endpoint': {},
                'requests_by_method': {},
                'response_times': [],
                'errors_total': 0,
                'errors_by_status': {},
                'cache_hits': 0,
                'cache_misses': 0,
                'active_connections': 0,
                'db_queries': 0
            }
            self.start_time = time.time()

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —Å–±–æ—Ä—â–∏–∫ –º–µ—Ç—Ä–∏–∫
_metrics_collector: Optional[MetricsCollector] = None

async def get_metrics_collector() -> MetricsCollector:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–±–æ—Ä—â–∏–∫ –º–µ—Ç—Ä–∏–∫"""
    global _metrics_collector
    
    if _metrics_collector is None:
        _metrics_collector = MetricsCollector()
    
    return _metrics_collector

# ===== –ö–û–ù–¢–ï–ö–°–¢–ù–´–ï –ú–ï–ù–ï–î–ñ–ï–†–´ =====

@asynccontextmanager
async def get_components() -> AsyncGenerator[Dict[str, Any], None]:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
    await ensure_initialized()
    
    components = {
        'data_manager': await get_data_manager(),
        'statistics': await get_statistics_calculator(),
        'analytics': await get_analytics_engine(),
        'cache': await get_cache_manager(),
        'metrics': await get_metrics_collector(),
        'rate_limiter': await get_rate_limiter()
    }
    
    try:
        yield components
    finally:
        # Cleanup –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        pass

# ===== –£–¢–ò–õ–ò–¢–´ =====

def get_client_ip(request: Request) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å IP –∞–¥—Ä–µ—Å –∫–ª–∏–µ–Ω—Ç–∞"""
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –ø—Ä–æ–∫—Å–∏
    forwarded_for = request.headers.get("X-Forwarded-For")
    if forwarded_for:
        return forwarded_for.split(",")[0].strip()
    
    real_ip = request.headers.get("X-Real-IP")
    if real_ip:
        return real_ip
    
    cf_connecting_ip = request.headers.get("CF-Connecting-IP")
    if cf_connecting_ip:
        return cf_connecting_ip
    
    return request.client.host

def get_user_agent(request: Request) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å User-Agent –∫–ª–∏–µ–Ω—Ç–∞"""
    return request.headers.get("User-Agent", "Unknown")

def get_request_info(request: Request) -> Dict[str, Any]:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø—Ä–æ—Å–µ"""
    return {
        'method': request.method,
        'url': str(request.url),
        'path': request.url.path,
        'query_params': dict(request.query_params),
        'headers': dict(request.headers),
        'client_ip': get_client_ip(request),
        'user_agent': get_user_agent(request),
        'timestamp': time.time()
    }

async def log_request(request: Request, response_time: float, status_code: int):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞"""
    client_ip = get_client_ip(request)
    user_agent = get_user_agent(request)
    
    logger.info(
        f"{request.method} {request.url.path} "
        f"- {status_code} - {response_time:.3f}s "
        f"- {client_ip} - {user_agent[:50]}..."
    )
    
    # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
    metrics = await get_metrics_collector()
    await metrics.record_request(
        request.method,
        request.url.path,
        response_time,
        status_code
    )

# ===== –§–û–ù–û–í–´–ï –ó–ê–î–ê–ß–ò =====

class BackgroundTaskManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á"""
    
    def __init__(self):
        self.tasks: Dict[str, asyncio.Task] = {}
        self.running = False
    
    async def start(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á"""
        if self.running:
            return
        
        self.running = True
        logger.info("üîÑ –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á...")
        
        # –ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞
        self.tasks['cache_cleanup'] = asyncio.create_task(self._cache_cleanup_task())
        
        # –ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –º–µ—Ç—Ä–∏–∫
        self.tasks['metrics_cleanup'] = asyncio.create_task(self._metrics_cleanup_task())
        
        logger.info("‚úÖ –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞–ø—É—â–µ–Ω—ã")
    
    async def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á"""
        if not self.running:
            return
        
        self.running = False
        logger.info("üõë –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á...")
        
        for name, task in self.tasks.items():
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        self.tasks.clear()
        logger.info("‚úÖ –§–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã")
    
    async def _cache_cleanup_task(self):
        """–ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞"""
        while self.running:
            try:
                await asyncio.sleep(300)  # –ö–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
                
                cache = await get_cache_manager()
                await cache.cleanup()
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –æ—á–∏—Å—Ç–∫–∏ –∫—ç—à–∞: {e}")
    
    async def _metrics_cleanup_task(self):
        """–ó–∞–¥–∞—á–∞ –æ—á–∏—Å—Ç–∫–∏ –º–µ—Ç—Ä–∏–∫"""
        while self.running:
            try:
                await asyncio.sleep(3600)  # –ö–∞–∂–¥—ã–π —á–∞—Å
                
                metrics = await get_metrics_collector()
                # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤ –ë–î
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ –∑–∞–¥–∞—á–µ –æ—á–∏—Å—Ç–∫–∏ –º–µ—Ç—Ä–∏–∫: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
_background_task_manager: Optional[BackgroundTaskManager] = None

async def get_background_task_manager() -> BackgroundTaskManager:
    """–ü–æ–ª—É—á–∏—Ç—å –º–µ–Ω–µ–¥–∂–µ—Ä —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á"""
    global _background_task_manager
    
    if _background_task_manager is None:
        _background_task_manager = BackgroundTaskManager()
    
    return _background_task_manager

# ===== –û–ß–ò–°–¢–ö–ê –†–ï–°–£–†–°–û–í =====

async def cleanup_resources():
    """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global _data_manager, _statistics_calculator, _analytics_engine, _redis_client, _db_engine
    global _cache_manager, _rate_limiter, _metrics_collector, _background_task_manager
    
    logger.info("üßπ –û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤...")
    
    try:
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
        if _background_task_manager:
            await _background_task_manager.stop()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        if _data_manager:
            await _data_manager.cleanup()
        
        if _statistics_calculator:
            await _statistics_calculator.cleanup()
        
        if _analytics_engine:
            await _analytics_engine.cleanup()
        
        # –û—á–∏—â–∞–µ–º –∫—ç—à
        if _cache_manager:
            await _cache_manager.clear()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º Redis
        if _redis_client and REDIS_AVAILABLE:
            await _redis_client.close()
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –ë–î
        if _db_engine and SQLALCHEMY_AVAILABLE:
            await _db_engine.dispose()
        
        logger.info("‚úÖ –†–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Ä–µ—Å—É—Ä—Å–æ–≤: {e}")

# ===== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ó–ê–í–ò–°–ò–ú–û–°–¢–ò =====

@lru_cache()
def get_settings():
    """–ü–æ–ª—É—á–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)"""
    return settings

def get_logger(name: str = __name__):
    """–ü–æ–ª—É—á–∏—Ç—å –ª–æ–≥–≥–µ—Ä —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏"""
    return logging.getLogger(name)

def require_api_key(api_key: str = None):
    """–¢—Ä–µ–±–æ–≤–∞—Ç—å API –∫–ª—é—á (–¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)"""
    def dependency(request: Request):
        key = request.headers.get("X-API-Key") or api_key
        if not key:
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail="API –∫–ª—é—á –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω"
            )
        return key
    return dependency

# ===== –í–ê–õ–ò–î–ê–¶–ò–Ø =====

def validate_request_size(max_size: int = 1024 * 1024):  # 1MB –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    """–í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∑–∞–ø—Ä–æ—Å–∞"""
    async def dependency(request: Request):
        content_length = request.headers.get("content-length")
        if content_length and int(content_length) > max_size:
            raise HTTPException(
                status_code=status.HTTP_413_REQUEST_ENTITY_TOO_LARGE,
                detail=f"–†–∞–∑–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–µ–≤—ã—à–∞–µ—Ç {max_size} –±–∞–π—Ç"
            )
        return True
    return dependency

# ===== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ü–†–ò –ò–ú–ü–û–†–¢–ï =====

async def startup_dependencies():
    """–ó–∞–ø—É—Å–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    await ensure_initialized()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ñ–æ–Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏
    task_manager = await get_background_task_manager()
    await task_manager.start()

async def shutdown_dependencies():
    """–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"""
    await cleanup_resources()
